{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation for Profile Omnifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.integrate import quad\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import utils\n",
    "from random import choices\n",
    "import profile_omnifold as pof\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "# Enable eager execution\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from keras.layers import Dense, Input, Concatenate\n",
    "from keras.models import Model\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, roc_auc_score\n",
    "dvc = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {dvc} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Gaussian Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smearing kernel for the MC data\n",
    "mu_kernel_mc = 0\n",
    "sigma1_kernel_mc = 1\n",
    "sigma2_kernel_mc = 1\n",
    "\n",
    "# smearing kernel for the experimental data\n",
    "mu_kernel_data = 0\n",
    "sigma1_kernel_data = 1\n",
    "sigma2_kernel_data = 1.5\n",
    "\n",
    "def k_mc(y,x):\n",
    "    return norm.pdf(y[:,0]-x[:,0],loc=mu_kernel_mc,scale=sigma1_kernel_mc)*norm.pdf(y[:,1]-x[:,0],loc=mu_kernel_mc,scale=sigma2_kernel_mc)\n",
    "\n",
    "def k_data(y,x):\n",
    "    return norm.pdf(y[:,0]-x[:,0],loc=mu_kernel_data,scale=sigma1_kernel_data)*norm.pdf(y[:,1]-x[:,0],loc=mu_kernel_data,scale=sigma2_kernel_data)\n",
    "\n",
    "# reweighting function w parametrized by theta (in this case, the standard deviation of the response kernel)\n",
    "def w_theta(y,x,theta):\n",
    "    return norm.pdf(y[:,0]-x[:,0],loc=mu_kernel_data,scale=sigma1_kernel_data)*norm.pdf(y[:,1]-x[:,0],loc=mu_kernel_data,scale=theta)/k_mc(y,x)\n",
    "\n",
    "# derivative of w with respect to theta\n",
    "def w_theta_derivative(y,x,theta):\n",
    "    return ((y[:,1]-x[:,0])**2/(theta**3)-1/theta)*w_theta(y,x,theta)\n",
    "\n",
    "# true reweighting function on the MC response kernel\n",
    "def w_true(y,x):\n",
    "    return k_data(y,x)/k_mc(y,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_data = 0.8\n",
    "sigma_data = 1\n",
    "\n",
    "def px(x):\n",
    "    return norm.pdf(x,loc=mu_data,scale=sigma_data)\n",
    "def py1(y):\n",
    "    return norm.pdf(y,loc=mu_data+mu_kernel_data,scale=np.sqrt(sigma_data**2+sigma1_kernel_data**2))\n",
    "def py2(y):\n",
    "    return norm.pdf(y,loc=mu_data+mu_kernel_data,scale=np.sqrt(sigma_data**2+sigma2_kernel_data**2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_mc = 0\n",
    "sigma_mc = 1\n",
    "\n",
    "\n",
    "def qx(x):\n",
    "    return norm.pdf(x,loc=mu_mc,scale=sigma_mc)\n",
    "def qy1(y):\n",
    "    return norm.pdf(y,loc=mu_mc+mu_kernel_mc,scale=np.sqrt(sigma_mc**2+sigma1_kernel_mc**2))\n",
    "def qy2(y):\n",
    "    return norm.pdf(y,loc=mu_mc+mu_kernel_mc,scale=np.sqrt(sigma_mc**2+sigma2_kernel_mc**2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, sharey=True, sharex=True, figsize=(15, 8))\n",
    "x = np.linspace(-7, 5, 1000)\n",
    "ax.plot(x, px(x),\n",
    "       'black', lw=3, alpha=0.6, label='experimental particle-level distribution')\n",
    "ax.plot(x, qx(x),\n",
    "       'lightblue', lw=3, alpha=0.6, label='Monte Carlo particle-level distribution')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "\n",
    "nsim = 10\n",
    "Ndata = 100000\n",
    "Nsim = 100000\n",
    "theta_list = []\n",
    "\n",
    "for i in range(nsim):\n",
    "    # sample from the experimental distribution\n",
    "    \n",
    "    x_data = np.random.normal(loc=mu_data,scale=sigma_data,size=Ndata).reshape(-1,1)\n",
    "    y_data1 = np.random.normal(loc=x_data[:,0]+mu_kernel_data,scale=sigma1_kernel_data,size=Ndata).reshape(-1,1)\n",
    "    y_data2 = np.random.normal(loc=x_data[:,0]+mu_kernel_data,scale=sigma2_kernel_data,size=Ndata).reshape(-1,1)\n",
    "    y_data = np.hstack([y_data1, y_data2])\n",
    "\n",
    "    # sample from the MC distribution\n",
    "\n",
    "    x_mc = np.random.normal(loc=mu_mc,scale=sigma_mc,size=Nsim).reshape(-1,1)\n",
    "    y_mc1 = np.random.normal(loc=x_mc[:,0]+mu_kernel_mc,scale=sigma1_kernel_mc,size=Nsim).reshape(-1,1)\n",
    "    y_mc2 = np.random.normal(loc=x_mc[:,0]+mu_kernel_mc,scale=sigma2_kernel_mc,size=Nsim).reshape(-1,1)\n",
    "    y_mc = np.hstack([y_mc1,y_mc2])\n",
    "\n",
    "    # true w function parametrized by theta\n",
    "    delta_epsilon = 1\n",
    "    theta_test = (sigma2_kernel_data-sigma2_kernel_mc)/delta_epsilon\n",
    "    def w_func(theta):\n",
    "       return w_theta(y_mc, x_mc, theta*delta_epsilon+sigma2_kernel_mc)\n",
    "    def w_func_derivative(theta):\n",
    "       return w_theta_derivative(y_mc, x_mc, theta*delta_epsilon+sigma2_kernel_mc)\n",
    "    \n",
    "    inputs = Input((1, ))\n",
    "    hidden_layer_1 = Dense(50, activation='relu')(inputs)\n",
    "    hidden_layer_2 = Dense(50, activation='relu')(hidden_layer_1)\n",
    "    hidden_layer_3 = Dense(50, activation='relu')(hidden_layer_2)\n",
    "    outputs = Dense(1, activation='sigmoid')(hidden_layer_3)\n",
    "\n",
    "    model_penalized = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # profile unfolding\n",
    "    mc = np.stack([x_mc[:,0], y_mc[:,0]], axis=1)\n",
    "    nu_profile_penalized_nn = pof.penalized_profile_omnifold(mc, y_data[:,0], 5, model_penalized, w_func, w_func_derivative, 0., 0., verbose=1)\n",
    "\n",
    "    sns.kdeplot(x=x_mc[:,0], ax=ax, color=\"orange\", weights=nu_profile_penalized_nn[4,1,:])\n",
    "    print(nu_profile_penalized_nn[:,3,0])\n",
    "    theta_list.append(nu_profile_penalized_nn[4,3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unfolding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
